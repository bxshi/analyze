2015-02-11 21:20:32,631 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: bshi
2015-02-11 21:20:32,633 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: bshi
2015-02-11 21:20:32,635 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(bshi); users with modify permissions: Set(bshi)
2015-02-11 21:20:33,461 [sparkDriver-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2015-02-11 21:20:34,086 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 65510.
2015-02-11 21:20:34,118 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2015-02-11 21:20:34,152 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2015-02-11 21:20:34,185 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /var/folders/xd/klsl6smd0k1bng2ftnkynmbc0000gn/T/spark-local-20150211212034-09e0
2015-02-11 21:20:34,194 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 491.7 MB
2015-02-11 21:20:35,739 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-02-11 21:20:35,907 [main] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /var/folders/xd/klsl6smd0k1bng2ftnkynmbc0000gn/T/spark-f65ebcf0-8289-44de-9524-ff4611ea584a
2015-02-11 21:20:35,917 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2015-02-11 21:20:36,142 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 65511.
2015-02-11 21:20:36,368 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2015-02-11 21:20:36,372 [main] INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://192.168.1.101:4040
2015-02-11 21:20:36,538 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@192.168.1.101:65510/user/HeartbeatReceiver
2015-02-11 21:20:36,793 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 65512
2015-02-11 21:20:36,797 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2015-02-11 21:20:36,799 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerMasterActor - Registering block manager localhost:65512 with 491.7 MB RAM, BlockManagerId(<driver>, localhost, 65512)
2015-02-11 21:20:36,803 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2015-02-11 21:20:37,466 [main] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(133168) called with curMem=0, maxMem=515553361
2015-02-11 21:20:37,476 [main] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 130.0 KB, free 491.5 MB)
2015-02-11 21:20:37,655 [main] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(18512) called with curMem=133168, maxMem=515553361
2015-02-11 21:20:37,655 [main] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 18.1 KB, free 491.5 MB)
2015-02-11 21:20:37,658 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:65512 (size: 18.1 KB, free: 491.7 MB)
2015-02-11 21:20:37,659 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_0_piece0
2015-02-11 21:20:37,666 [main] INFO  org.apache.spark.SparkContext - Created broadcast 0 from textFile at Main.scala:23
2015-02-11 21:20:39,177 [main] INFO  org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2015-02-11 21:20:39,378 [main] INFO  org.apache.spark.SparkContext - Starting job: reduce at Main.scala:25
2015-02-11 21:20:39,409 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (reduce at Main.scala:25) with 2 output partitions (allowLocal=false)
2015-02-11 21:20:39,410 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: Stage 0(reduce at Main.scala:25)
2015-02-11 21:20:39,411 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2015-02-11 21:20:39,421 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2015-02-11 21:20:39,435 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[3] at map at Main.scala:25), which has no missing parents
2015-02-11 21:20:39,472 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2896) called with curMem=151680, maxMem=515553361
2015-02-11 21:20:39,473 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 491.5 MB)
2015-02-11 21:20:39,475 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2060) called with curMem=154576, maxMem=515553361
2015-02-11 21:20:39,476 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.0 KB, free 491.5 MB)
2015-02-11 21:20:39,477 [sparkDriver-akka.actor.default-dispatcher-14] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:65512 (size: 2.0 KB, free: 491.7 MB)
2015-02-11 21:20:39,478 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_1_piece0
2015-02-11 21:20:39,479 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:838
2015-02-11 21:20:39,512 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[3] at map at Main.scala:25)
2015-02-11 21:20:39,514 [sparkDriver-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
2015-02-11 21:20:39,563 [sparkDriver-akka.actor.default-dispatcher-14] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, ANY, 1319 bytes)
2015-02-11 21:20:39,568 [sparkDriver-akka.actor.default-dispatcher-14] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, ANY, 1319 bytes)
2015-02-11 21:20:39,574 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2015-02-11 21:20:39,574 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2015-02-11 21:20:39,610 [Executor task launch worker-1] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dsg1.crc.nd.edu/user/bshi/dblp/citation_edge.txt:29855759+29855760
2015-02-11 21:20:39,610 [Executor task launch worker-0] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dsg1.crc.nd.edu/user/bshi/dblp/citation_edge.txt:0+29855759
2015-02-11 21:20:39,627 [Executor task launch worker-0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-02-11 21:20:39,627 [Executor task launch worker-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-02-11 21:20:39,627 [Executor task launch worker-0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-02-11 21:20:39,627 [Executor task launch worker-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-02-11 21:20:39,627 [Executor task launch worker-0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-02-11 21:20:39,628 [Executor task launch worker-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
